{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d9bc88",
   "metadata": {},
   "source": [
    "# Instrument classifer\n",
    "\n",
    "To download images with Bing Image Search, sign up at [Microsoft Azure](https://azure.microsoft.com/en-us/services/cognitive-services/bing-web-search-api/) for a free account. You will be given a key, which you can copy and enter in a cell as follows (replacing 'XXX' with your key and executing it):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861f1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b07d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.environ.get('AZURE_SEARCH_KEY', 'f53145dbfaa54d75993489efd38190c4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f762100",
   "metadata": {},
   "source": [
    "Next lets define the instruments types and determinate a path to store the images dowloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b75bee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "instrument_types = 'guitar','piano','trumpet'\n",
    "path = Path('instruments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb36f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for o in instrument_types:\n",
    "        dest = (path/o)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        results = search_images_bing(key, o)\n",
    "        download_images(dest, urls=results.attrgot('contentUrl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a8f04e",
   "metadata": {},
   "source": [
    "Its important that the we do not get corrupted images, so lets verify and clean the images unsing Path.unlink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f38e466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#426) [Path('instruments/guitar/00f26183-0a2c-4214-8681-9b46eac0ad73.jpg'),Path('instruments/guitar/02f7dba8-27e9-4916-b453-6544bfc573fa.jpg'),Path('instruments/guitar/04d06265-0b60-45e5-a801-3bb7aa927033.jpg'),Path('instruments/guitar/0eac5f94-a765-4c0f-b244-f223d3bf5bfc.jpg'),Path('instruments/guitar/0fd824fa-524b-4eae-b595-6a106488338b.jpg'),Path('instruments/guitar/112d3f29-29d0-468c-9332-c14008bbca1c.jpg'),Path('instruments/guitar/1246c4c0-8284-465b-868b-d773b9f614d4.jpg'),Path('instruments/guitar/1263a2e3-d8dd-42e4-bd49-d5b241a20ea5.jpg'),Path('instruments/guitar/12fcb465-f2d5-4cb4-812b-2656ff822326.jpg'),Path('instruments/guitar/15ab45f7-2e1c-4371-bf7a-645047f615e7.jpg')...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns = get_image_files(path)\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c6d65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [Path('instruments/guitar/2c10a594-18d4-4d3c-805a-521d1987e032.jpg'),Path('instruments/piano/4a3150e6-6557-408a-9bf8-c80733e4adac.jpg'),Path('instruments/piano/5281397c-e562-4a84-80cc-0f15a3b35fc2.jpg'),Path('instruments/piano/6f646d36-dbf7-488c-8691-942e591a7312.jpg'),Path('instruments/trumpet/0d3294dc-f85e-4725-8164-c96b34de6787.jpg')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed = verify_images(fns)\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f0ee79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [None,None,None,None,None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed.map(Path.unlink)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78309896",
   "metadata": {},
   "source": [
    "Now lets train our model with some configuration, first we transform the itens by cropping them with minimal values defined, and we also uses data augmentation techniques to diversify the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab7b51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7730b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = instruments.new(\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms())\n",
    "dls = instruments.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad1808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gatos\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gatos\\miniconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.421016</td>\n",
       "      <td>0.038399</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>01:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gatos\\miniconda3\\lib\\site-packages\\PIL\\Image.py:959: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/4 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.00% [1/5 00:07<00:29]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a276813",
   "metadata": {},
   "source": [
    "Now we need to check all missing images and ensure that nothing is wrong with the image labels, first we will take a look on the confusion matrix, after we will show all images with the most loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c363fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96985eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1ca0b",
   "metadata": {},
   "source": [
    "Now, lets export our model to use it on some application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0dc866",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6f49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path()\n",
    "path.ls(file_exts='.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf396f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf.predict('some image path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44224b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
